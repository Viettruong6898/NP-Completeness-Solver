# NP-Completeness Solver

This project was used to solve NP-completeness problems. For example, consider the following problem:

 "You are at a wizard party hosted by Trump and Obama. As usual, wizards are shy about discussing
their age. From conversations at the party, you are only given information in the following form: some
wizardâ€™s age is not betIen the ages of two other wizards. Since wizard parties are also notoriously long
(an entire month!), you decide to use your time at the party to write a solver and figure out the true ordering
of wizards by their ages. All the input files passed in are as followed. Line (1) # of wizards Line (2) # of constraints Line(3~) List of constraints. Write an output file that satisfies all the constraints and return the optimal ordering"

As you can see if the number of wizards go up to 500 or more and you are given 500 constraints or more, there are an exponential amount of possibilities. This is why this problem is in NP-complete. Therefore, I will solve this problem by randomly generating combinations and update the best state possible until all constraints are satisfied. I can solve these input files in seconds because I optimized it by moving one wizard around at a time and see which constraints are broken.

More information about how this solver works is as follows:

I decided to use the simulated annealing optimization library on Github (https://github.com/perrygeo/simanneal). However, the solution generated by this module is too slow since the swapping function isn't efficient; therefore, I optimized it better. The module efficiently solves the TSP problem and thus I reduce our Wizard Party Problem(WPP) to TSP. The algorithm finds the initial condition by randomizing and then keep that as the current best state. The module searches for the optimal state of a system by moving one random wizard using a random number generator. For faster runtime on our input files, I also used PyPy: a fast and compliant alternative implementation of the Python language.

The reason why simulated annealing is a good algorithm for solving the WPP is that it avoids getting caught in a local maxima/minimum. One challenge of the WPP is that moving one Wizard may break any arbitrary and unpredictable number of other constraints, as Ill as solve any number of constraints. Given this, the absolute minimum would be hidden in a very dense graph of wild oscillations, with many local maximums and local minimums to parse through. Using simulated annealing, I can attempt to find the true minimum. The true minimum varies by temperature, so I used one of the functions in the library called auto_schedule to generate an optimal maximum temperature, minimum temperature, and number of steps needed to generate the optimal solution.

I used memoization to save processing time by remembering the previous energy level, and preprocessed a dictionary with wizard names as the key and a list of all constraints involving that wizard as the value. Before I move the wizard, I keep track of the current number of constraints failing, as Ill as the wizard name. This will allow us to recalculate, after the move, the number of constraints involving that wizard that fail, and obtain a difference of number of the failing constraints. Using this difference and the previous energy level, I can determine whether a move was better or worse. If it is worse, do not update the previous energy level. If it is better, update the previous energy level and check to see it the current energy level is better than the best energy level (in which case, update the variable). By doing all of the above, I can avoid constantly having to recalculate energy levels using all of the constraints, saving us a significant amount of time.

The process of simulated annealing optimization goes as follows: 
1. I generate our initial state by reading the input file from top to bottom.
2. I run the auto_schedule function on that state to get an optimal maximum temperature, minimum temperature, and number of steps needed to generate the optimal solution (this varies by input files).
3. Using these values as initial values, I randomly change the list of wizards (alter the state of the list) with the move function. In our case, I move a single wizard and insert him/her back into the list at a random index. Before you actually move the wizard though, record the number of constraints that are currently being satisfied by the list.
4. I assess the energy of the new list. In our case, the energy is the number of constraints the list of wizards does not pass (since I want to minimize our energy and be consistent with the framework). I used memoization to avoid checking all the constraints every time I try to measure the energy. Using the knowledge that, by moving only one wizard, the only constraints that may break or pass must involve the wizard that was moved, I can avoid checking all of the constraints.
5. I then compare the energy to the previous energy and decide whether to accept the new list or reject it, based on the current temperature.
6. I repeated this process until I have passed all constraints.

*Most credit goes to perrygeo for formulating the simulated annealing optimzation library. I just helped speed up the process by efficiently manipulating the constraints and wizards*


